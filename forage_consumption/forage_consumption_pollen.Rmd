---
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

Reminder: the csvs imported for analysis are linked from the output of data_transformation_cleaning, not db as usual. 

```{r}
pollen_consumption <- read.csv("./input/pollen_consumption.csv")
```

Ensure variables have correct class. 

```{r}
# make sure variable classes are correct
pollen_consumption$block <- as.factor(pollen_consumption$block)
class(pollen_consumption$block)

pollen_consumption$treatment <- as.factor(pollen_consumption$treatment)
class(pollen_consumption$treatment)

pollen_consumption$triad <- as.factor(pollen_consumption$triad)
class(pollen_consumption$triad)

class(pollen_consumption$summed_consumption)

pollen_consumption$number_of_workers_at_exposure_start <- as.numeric(pollen_consumption$number_of_workers_at_exposure_start)
class(pollen_consumption$number_of_workers_at_exposure_start)
```

Sort out the cleveland dotplot encoding. 

```{r}
# for a cleveland dotplot to work treatment has to be coded 1-3. 
pollen_consumption$clevelandcode <- 0 

for (i in 1:nrow(pollen_consumption)) {
  
  if (pollen_consumption$treatment [i] == "control") {
    
    pollen_consumption$clevelandcode [i] <- 1
    
  }
  
  if (pollen_consumption$treatment [i] == "flup") {
    
    pollen_consumption$clevelandcode [i] <- 2
    
    }
  
  if (pollen_consumption$treatment [i] == "sivanto") {
    
    pollen_consumption$clevelandcode [i] <- 3
    
    }
  
}

# should be numeric already anyway
pollen_consumption$clevelandcode <- as.numeric(pollen_consumption$clevelandcode)
```

Use a cleveland dotplot to identify any obvious outliers. 

```{r}
dotchart(pollen_consumption$summed_consumption,
         groups = factor(pollen_consumption$clevelandcode),
         ylab = "Order of observations",
         xlab = "Consumption (mg)", main = "Cleveland dotplot", pch = pollen_consumption$clevelandcode)
```

It does look like there are two potential outliers. Sivanto could be lower than the other two groups. Also, the other two groups look like they are separated into two distinct clusters? That's odd. Investigate. 

Have a look at a boxplot.

```{r}
boxplot(summed_consumption ~ treatment,
        varwidth = TRUE, xlab = "Treatment",
        main = "Boxplot of Consumption Conditional on Treatment", 
        ylab = "Consumption", data = pollen_consumption)
```

Again, sivanto does look lower than the other two and one of the outliers is apparent again. May be the case where I perform the analysis twice, once with and once without the outliers to see if they have any serious influence. There is no biological reason to discount these colonies like there was for C17 in the sucrose analysis. 

Also want to show consumption vs number_of_workers_exposure_start for each treatment. For the plots below the panels are filled from bottom to top and left to right. So for summed_consumption vs number_of_workers_at_exposure_start the bottom left is control, bottom right is flup, top right is sivanto.

```{r}
# by treatment
coplot(summed_consumption ~ number_of_workers_at_exposure_start | treatment, data = pollen_consumption)

plot(x = pollen_consumption$number_of_workers_at_exposure_start,
     y = pollen_consumption$summed_consumption,
     col = pollen_consumption$treatment,
     xlab = "starting_worker_number",
     ylab = "pollen_consumption")
```

C17 is again an outlier when starting worker number is examined. Again I will exclude it as the queen died in the dosage window early on. 

```{r}
# remove C17
pollen_consumption <- pollen_consumption [pollen_consumption$colony_number != "17", ]

# two values 50% larger than 3rd largest value. 
# pollen_consumption <- pollen_consumption [pollen_consumption$colony_number != "76", ]
# pollen_consumption <- pollen_consumption [pollen_consumption$colony_number != "117", ]

# fit beyond optimal model with gls
library(nlme)

M1 <- lm(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML")

# unhash this for the summary
summary(M1)

# extract residuals from this model. At this stage the ordinary residuals are fine.
# once a variance structure has been applied we'll have to use standardised residuals
# where the ordinary residuals are divided by the square root of the variance. 
# NOTE - standardised residuals = normalised residuals = Pearson residuals (if Poisson GLM).
E <- resid(M1)

# plot residual vs fitted
plot(M1, which = c (1), abline = 0)

# plot residual vs treatment
boxplot(E ~ pollen_consumption$treatment, main = "Treatment")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start
plot(x = pollen_consumption$number_of_workers_at_exposure_start,
     y = E,
     col = pollen_consumption$treatment,
     xlab = "starting_worker_number",
     ylab = "Ordinary Residuals")

# plot residual vs number_of_workers_at_exposure_start by treatment
coplot(E ~ number_of_workers_at_exposure_start | treatment,
       ylab = "Ordinary residuals", data = pollen_consumption)
```

Using lm a line is added to the residual vs fitted, which aids pattern detection. There is a pattern in my residuals where the residuals are negative for small and large fitted values. The simplest fix is to add a quadratic term to combat this apparent non-linearity. Other fixes are to add more explanatory variables, interaction terms, perform a transformation or apply smoothers. 

```{r}
# does a quadratic term solve the residual pattern?
M1_quad <- lm(summed_consumption ~ treatment + number_of_workers_at_exposure_start + I(number_of_workers_at_exposure_start^2) + treatment:number_of_workers_at_exposure_start + treatment:I(number_of_workers_at_exposure_start^2),
          data = pollen_consumption, method = "REML")

# extract residuals from this model. At this stage the ordinary residuals are fine.
# once a variance structure has been applied we'll have to use standardised residuals
# where the ordinary residuals are divided by the square root of the variance. 
# NOTE - standardised residuals = normalised residuals = Pearson residuals (if Poisson GLM).
E_quad <- resid(M1_quad)

# plot residual vs fitted
plot(M1_quad, which = c (1), abline = 0)

# plot residual vs treatment
boxplot(E_quad ~ pollen_consumption$treatment, main = "Treatment")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start
plot(x = pollen_consumption$number_of_workers_at_exposure_start,
     y = E_quad,
     col = pollen_consumption$treatment,
     xlab = "starting_worker_number",
     ylab = "Ordinary Residuals")

# plot residual vs number_of_workers_at_exposure_start by treatment
coplot(E_quad ~ number_of_workers_at_exposure_start | treatment,
       ylab = "Ordinary residuals", data = pollen_consumption)
```

The residuals vs fitted still has this pattern in it. I don't think this pattern is strong enough to cause any alarm.

```{r, eval=FALSE}
M2 <- lm(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML")

# unhash this for the summary
summary(M2)

# extract residuals from this model. At this stage the ordinary residuals are fine.
# once a variance structure has been applied we'll have to use standardised residuals
# where the ordinary residuals are divided by the square root of the variance. 
# NOTE - standardised residuals = normalised residuals = Pearson residuals (if Poisson GLM).
E2 <- resid(M2)

# plot residual vs fitted
plot(M2, which = c (1), abline = 0)

# plot residual vs treatment
boxplot(E2 ~ pollen_consumption$treatment, main = "Treatment")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start
plot(x = pollen_consumption$number_of_workers_at_exposure_start,
     y = E2,
     col = pollen_consumption$treatment,
     xlab = "starting_worker_number",
     ylab = "Ordinary Residuals")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start by treatment
coplot(E2 ~ number_of_workers_at_exposure_start | treatment,
       ylab = "Ordinary residuals", data = pollen_consumption)
```

Is block necessary? No.

```{r}
library(lme4)

# redefine with gls
M2 <- gls(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML")

M3 <- lme(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
              data = pollen_consumption,
              random =~ 1 | block, method = "REML")

anova(M2, M3)
```

Variance seems to increase with starting worker number so try a varPower and varExp function. Both are nested with M2 as setting delta to 0 yields Ïƒ2.

```{r}
# redefine with gls
M2 <- gls(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML")

# summary(M2)

# varExp function
M4 <- gls(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML", weights = varExp(form =~ number_of_workers_at_exposure_start))
anova(M2, M4)

# varPower function
M5 <- gls(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML", weights = varPower(form =~ number_of_workers_at_exposure_start))
anova(M2,M5)

# summary(M5)
```

No support for adding a variance structure that allows variance to increase with starting worker number. Have a look at the residual plots for M5. 

```{r}
E5 <- resid(M5, type = "normalized")

# plot residual vs fitted
plot(M5, which = c (1), abline = 0, )

# plot residual vs treatment
boxplot(E5 ~ pollen_consumption$treatment, main = "Treatment")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start
plot(x = pollen_consumption$number_of_workers_at_exposure_start,
     y = E5,
     col = pollen_consumption$treatment,
     xlab = "starting_worker_number",
     ylab = "Stand. Residuals")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start by treatment
coplot(E5 ~ number_of_workers_at_exposure_start | treatment,
       ylab = "Stand. Residuals", data = pollen_consumption)
```

I can't see much difference in the residual vs fitted plot.

Back to the current step. Have now got our random structure sorted:

M2 <- gls(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "REML")

Time for model selection to find the optimal fixed structure for the selected random structure. Perform using likelihood ratio tests of nested models.

```{r}
# this is our starting model.
M5 <- gls(summed_consumption ~ treatment + number_of_workers_at_exposure_start + treatment:number_of_workers_at_exposure_start,
          data = pollen_consumption, method = "ML")

# test significance of interaction term
M5a <- update(M5, .~. -treatment:number_of_workers_at_exposure_start)
anova(M5, M5a)

# drop it. M5a ref
M5aa <- update(M5a, .~. -treatment)
anova(M5a, M5aa)

M5ab <- update(M5a, .~. -number_of_workers_at_exposure_start)
anova(M5a, M5ab)

# treatment is not significant but include in the model as part of experiment.
```


Final model. Centre starting worker number so intercept is more useful.

```{r}
pollen_consumption$number_of_workers_at_exposure_start_centred <- pollen_consumption$number_of_workers_at_exposure_start - mean(pollen_consumption$number_of_workers_at_exposure_start)
```

```{r}
M_final <- lm(summed_consumption ~ number_of_workers_at_exposure_start_centred + treatment,
          data = pollen_consumption)

summary(M_final)

# take a look at the residual plots
E_final <- resid(M_final, type = "response")

# plot residual vs fitted
plot(M_final)

# plot residual vs treatment
boxplot(E_final ~ pollen_consumption$treatment, main = "Treatment")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start
plot(x = pollen_consumption$number_of_workers_at_exposure_start,
     y = E_final,
     col = pollen_consumption$treatment,
     xlab = "starting_worker_number",
     ylab = "Stand. Residuals")
abline(0, 0)

# plot residual vs number_of_workers_at_exposure_start by treatment
coplot(E_final ~ number_of_workers_at_exposure_start | treatment,
       ylab = "Stand. Residuals", data = pollen_consumption)
```

Interpretation. Treatment has no effect on pollen consumption. As starting worker number increases pollen consumption increases.  

Plot Model Output

```{r}
library(tidyverse)

predictions <- as.data.frame(predict(M_final, se.fit = TRUE))

pollen_consumption$prediction <- predictions$fit

pollen_consumption$se <- predictions$se.fit

treatment_levs <- unique(pollen_consumption$treatment)

treatment_preds_df <- tibble()

for (i in 1:length(treatment_levs)) {
  
  # order predictions according to treatment
  treatment_preds <- pollen_consumption [pollen_consumption$treatment == treatment_levs [i],]
  
  # keep only the columns of interest
  treatment_preds <- treatment_preds [, c(3,12,15,16)]
  
  # sort values by number of workers size
  treatment_preds <- treatment_preds [order(treatment_preds$number_of_workers_at_exposure_start),]
  
  treatment_preds_df <- rbind(treatment_preds_df, treatment_preds)
  
}

model_preds <- ggplot() + 
      geom_point(data = pollen_consumption, aes(x = number_of_workers_at_exposure_start, y = summed_consumption, color = treatment)) +
      geom_line(data = treatment_preds_df, aes(x = number_of_workers_at_exposure_start, y = prediction, group = treatment, color = treatment)) +
      geom_ribbon(data = treatment_preds_df, aes(x = number_of_workers_at_exposure_start,
                                                 y = prediction,
                                                 ymin = prediction - (1.96*se),
                                                ymax = prediction + (1.96*se),
                                                group = treatment,
                                                color = treatment,
                                                 fill = treatment),
                  alpha = 0.3) +
      theme_bw() +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
      scale_color_manual(values=c("#117733", "#332288", "#AA4499"), name = "Treatment", labels = c("Control", "FPF", "Sivanto")) +
      scale_fill_manual(values=c("#117733", "#332288", "#AA4499"), name = "Treatment", labels = c("Control", "FPF", "Sivanto")) +
      xlab("Starting Worker Number") +
      ylab("Pollen Consumption (mg)") +
      ggtitle("Aggregate pollen consumption during the exposure window did not differ between treatment groups")

model_preds
```

Below shows why block was not used. There was no variance between blocks. This can happen when there are a small number of random effect levels (like 5). If a variance component is zero, dropping it from the model will have no effect on any of the estimated quantities (although it will affect the AIC, as the variance parameter is counted even though it has no effect). Pasch, Bolker, and Phelps (2013) gives one example where random effects were dropped because the variance components were consistently estimated as zero. Conversely, if one chooses for philosophical grounds to retain these parameters, it wonâ€™t change any of the answers.

```{r}
library(lme4)

M_final <- lmer(summed_consumption ~ number_of_workers_at_exposure_start_centred + treatment + (1|block),
          data = pollen_consumption)

summary(M_final)
```

